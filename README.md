# SHL Assessment Recommendation Engine  
*A lightweight Retrieval-Augmented recommendation system built using SHLâ€™s Product Catalog*

---

## ğŸ“Œ Overview  
This project recommends the most relevant SHL Assessments based on a userâ€™s job description or hiring requirement.  
The system uses:

- Scraped SHL product catalog (mandatory per assignment)
- SentenceTransformer embeddings
- Cosine similarity for ranking
- A simple and clean Gradio UI

The goal is to quickly map a hiring query â†’ suitable SHL assessments.

---

## ğŸ› ï¸ Tech Stack  
- **Python**
- **BeautifulSoup4** (Web scraping)
- **SentenceTransformer (all-MiniLM-L6-v2)** (Embeddings)
- **Torch**
- **Pandas / NumPy**
- **Gradio** (Frontend UI)

---

## ğŸ“‚ Project Structure  

```
project/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                         # Main Gradio app
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Gen_AI Dataset.xlsx            # Provided SHL dataset
â”‚   â”œâ”€â”€ shl_catalog_full_details.csv   # Scraped catalog (408 items)
â”‚   â””â”€â”€ shl_individual_tests_catalog.csv
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ catalog_embeddings.pt          # Model-generated embeddings
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ notebook.ipynb                 # Development & experiments
â”‚
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ scrape_shl_catalog.py          # Web scraper for SHL catalog
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§¹ Step 1 â€” Data Ingestion (Scraping)

SHL does not offer a public API, so the catalog is scraped **directly from the official SHL website** using BeautifulSoup.  
This satisfies the mandatory requirement:

> â€œSolutions built without scraping and storing SHL product catalog from the website will be rejected.â€

The scraper navigates through all pagination pages for:
- **Pre-packaged Job Solutions**  
- **Individual Test Solutions**

Total collected items: **408**

Output file:  
`data/shl_catalog_full_details.csv`

---

## ğŸ” Step 2 â€” Embedding Generation  

We encode each SHL product using the model:

**Model Used:** `all-MiniLM-L6-v2`  
(Chosen because it is small, fast, and stable for cosine similarity)

Each product name â†’ embedding vector of shape:

```
[408, 384]
```

Saved to:  
`embeddings/catalog_embeddings.pt`

---

## ğŸ¤– Step 3 â€” Query â†’ Recommendations

Whenever the user enters a job description:

1. Query is converted to embedding  
2. Cosine similarity is computed against all catalog embeddings  
3. Top-K matching assessments are returned  

Ranking criteria: **Higher cosine score = higher similarity**

---

## ğŸ–¥ï¸ Step 4 â€” Gradio Web App

A simple UI asks:

1. **Job description / requirement**
2. **Number of suggestions (Top-K)**

Output:  
A clean table showing:

| Assessment Name | URL | Score |

Run the app using:

```
python app/app.py
```

---

## ğŸš€ How to Run Locally

### 1. Install dependencies  
```
pip install -r requirements.txt
```

### 2. Run the scraper (optional)  
```
python scraper/scrape_shl_catalog.py
```

### 3. Regenerate embeddings (optional)  
Run the notebook once, or use:

```
model.encode(...)
torch.save(...)
```

### 4. Start the application  
```
python app/app.py
```

---

## ğŸ§ª Testing

- All results are deterministic  
- File paths kept relative for easy SHL automated testing  
- Links remain publicly accessible  
- No external API dependencies â†’ fully offline capable

---

## ğŸ“„ Notes

- The project meets all SHL requirements:
  âœ“ Scraped data  
  âœ“ Structured catalog  
  âœ“ Embedding-based retrieval  
  âœ“ Working recommendation engine  
  âœ“ Clean UI  
  âœ“ Reproducible pipeline  

- Codebase is intentionally lightweight to ensure fast runtime.

---

## ğŸ‘¤ Author  
Built as part of the **SHL AI Internship Assignment**, with focus on clarity, correctness, and practical retrieval performance.

